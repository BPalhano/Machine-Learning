{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e308d4b1",
   "metadata": {},
   "source": [
    "# Data Processing by Scikit-Learning\n",
    "\n",
    "This notebook is based in the process showned in \"*Hands-On Machine Learning with Scikit-Learn and Keras*\", by O'Rilley, the code example can be found in the second chapter of this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9013d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell you will found all packages used for this pipeline.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import urllib\n",
    "import tarfile\n",
    "# all sckit-learn and keras function will be imported in the cell i use this one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e8930",
   "metadata": {},
   "source": [
    "Recap:  ([reference](https://github.com/BPalhano/Machine-Learning/blob/main/Chapter.2/Basic%20Dataset%20Analysis.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b776123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20433.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.569704</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.870553</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.003532</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.385070</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.490000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
       "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
       "std        2.003532      2.135952           12.585558   2181.615252   \n",
       "min     -124.350000     32.540000            1.000000      2.000000   \n",
       "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
       "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
       "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
       "mean       537.870553   1425.476744    499.539680       3.870671   \n",
       "std        421.385070   1132.462122    382.329753       1.899822   \n",
       "min          1.000000      3.000000      1.000000       0.499900   \n",
       "25%        296.000000    787.000000    280.000000       2.563400   \n",
       "50%        435.000000   1166.000000    409.000000       3.534800   \n",
       "75%        647.000000   1725.000000    605.000000       4.743250   \n",
       "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        20640.000000  \n",
       "mean        206855.816909  \n",
       "std         115395.615874  \n",
       "min          14999.000000  \n",
       "25%         119600.000000  \n",
       "50%         179700.000000  \n",
       "75%         264725.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just coping the dataset acess method of the previous notebook, see the link in the Markdown cell\n",
    "# above this one.\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path =os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()\n",
    "    \n",
    "def load_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "fetch_housing_data()\n",
    "data = load_data()\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24febae5",
   "metadata": {},
   "source": [
    "And let's generate the ``strat_train_set``again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd65fd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16354.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.575635</td>\n",
       "      <td>35.639314</td>\n",
       "      <td>28.653404</td>\n",
       "      <td>2622.539789</td>\n",
       "      <td>534.914639</td>\n",
       "      <td>1419.687379</td>\n",
       "      <td>497.011810</td>\n",
       "      <td>3.875884</td>\n",
       "      <td>207005.322372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.001828</td>\n",
       "      <td>2.137963</td>\n",
       "      <td>12.574819</td>\n",
       "      <td>2138.417080</td>\n",
       "      <td>412.665649</td>\n",
       "      <td>1115.663036</td>\n",
       "      <td>375.696156</td>\n",
       "      <td>1.904931</td>\n",
       "      <td>115701.297250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.940000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1443.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>784.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>2.566950</td>\n",
       "      <td>119800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.510000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2119.000000</td>\n",
       "      <td>433.000000</td>\n",
       "      <td>1164.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>3.541550</td>\n",
       "      <td>179500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.720000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3141.000000</td>\n",
       "      <td>644.000000</td>\n",
       "      <td>1719.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>4.745325</td>\n",
       "      <td>263900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>5358.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  16512.000000  16512.000000        16512.000000  16512.000000   \n",
       "mean    -119.575635     35.639314           28.653404   2622.539789   \n",
       "std        2.001828      2.137963           12.574819   2138.417080   \n",
       "min     -124.350000     32.540000            1.000000      6.000000   \n",
       "25%     -121.800000     33.940000           18.000000   1443.000000   \n",
       "50%     -118.510000     34.260000           29.000000   2119.000000   \n",
       "75%     -118.010000     37.720000           37.000000   3141.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \\\n",
       "count    16354.000000  16512.000000  16512.000000   16512.000000   \n",
       "mean       534.914639   1419.687379    497.011810       3.875884   \n",
       "std        412.665649   1115.663036    375.696156       1.904931   \n",
       "min          2.000000      3.000000      2.000000       0.499900   \n",
       "25%        295.000000    784.000000    279.000000       2.566950   \n",
       "50%        433.000000   1164.000000    408.000000       3.541550   \n",
       "75%        644.000000   1719.000000    602.000000       4.745325   \n",
       "max       6210.000000  35682.000000   5358.000000      15.000100   \n",
       "\n",
       "       median_house_value  \n",
       "count        16512.000000  \n",
       "mean        207005.322372  \n",
       "std         115701.297250  \n",
       "min          14999.000000  \n",
       "25%         119800.000000  \n",
       "50%         179500.000000  \n",
       "75%         263900.000000  \n",
       "max         500001.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"income_cat\"] = np.ceil(data[\"median_income\"] / 1.5)\n",
    "data[\"income_cat\"].where(data[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"income_cat\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]\n",
    "    \n",
    "for set in (strat_train_set, strat_test_set):\n",
    "    set.drop([\"income_cat\"], axis=1, inplace=True)\n",
    "    \n",
    "strat_train_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b45f78",
   "metadata": {},
   "source": [
    "Then, let's copy this variable to build our Data Processing Pipeline! We can clean this dataset and drop some features before copy the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e73155a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     16512.000000\n",
       "mean     207005.322372\n",
       "std      115701.297250\n",
       "min       14999.000000\n",
       "25%      119800.000000\n",
       "50%      179500.000000\n",
       "75%      263900.000000\n",
       "max      500001.000000\n",
       "Name: median_house_value, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "housing_labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb63822",
   "metadata": {},
   "source": [
    "Let's start the Data Cleaning. We have a feature ``total_bedrooms`` with some missing values. We have 3 approachs for this:\n",
    "\n",
    "1. Get rid of the corresponding districts.\n",
    "2. Get rid of the whole attribute.\n",
    "3. Set the values to some value (zero, the mean, the median, etc.)\n",
    "\n",
    "+ (Igor's comment: We have a fourth approach: falsificate the data using Generative Neural Networks for interpolate or extrapolate the dataset!)\n",
    "\n",
    "We can accomplish these easily using DataFrame's ``dropna()``, ``drop()`` and ``fillna()`` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea83c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.dropna(subset=[\"total_bedrooms\"]) # first approach\n",
    "\n",
    "housing.drop(\"total_bedrooms\", axis=1) # second approach\n",
    "\n",
    "median = housing[\"total_bedrooms\"].median() # third approach \n",
    "housing[\"total_bedrooms\"].fillna(median, inplace=True)\n",
    "\n",
    "# the fourth approach deserves a notebook only for it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f0d4a",
   "metadata": {},
   "source": [
    "A another approach is use the ``SimpleImputer`` function of ``Scikit-Learn`` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f486e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing function:\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# then, create a SimpleImputer instance, specifying that you want to replace \n",
    "# each attribute's missing values with tthe median of the attribute:\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88463ea",
   "metadata": {},
   "source": [
    "Since the median can only be computed on numerical attributes, you need to create a copy of the data without the text attribute ``ocean_proximity``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4304c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83eb287",
   "metadata": {},
   "source": [
    "Now, we can fit the imputer instance to the training data using the fit() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c54374d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-118.51   ,   34.26   ,   29.     , 2119.     ,  433.     ,\n",
       "       1164.     ,  408.     ,    3.54155])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(housing_num)\n",
    "\n",
    "# Let's see the imputer.statistics_:\n",
    "\n",
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7f643",
   "metadata": {},
   "source": [
    "Now, we can use this \"trained\" imputer to transform the training set by replacing missing values with the learned medians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64c761c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>16512.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-119.575635</td>\n",
       "      <td>35.639314</td>\n",
       "      <td>28.653404</td>\n",
       "      <td>2622.539789</td>\n",
       "      <td>533.939438</td>\n",
       "      <td>1419.687379</td>\n",
       "      <td>497.011810</td>\n",
       "      <td>3.875884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.001828</td>\n",
       "      <td>2.137963</td>\n",
       "      <td>12.574819</td>\n",
       "      <td>2138.417080</td>\n",
       "      <td>410.806260</td>\n",
       "      <td>1115.663036</td>\n",
       "      <td>375.696156</td>\n",
       "      <td>1.904931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-124.350000</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.499900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-121.800000</td>\n",
       "      <td>33.940000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1443.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>784.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>2.566950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-118.510000</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2119.000000</td>\n",
       "      <td>433.000000</td>\n",
       "      <td>1164.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>3.541550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-118.010000</td>\n",
       "      <td>37.720000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>3141.000000</td>\n",
       "      <td>641.000000</td>\n",
       "      <td>1719.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>4.745325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-114.310000</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>5358.000000</td>\n",
       "      <td>15.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          longitude      latitude  housing_median_age   total_rooms  \\\n",
       "count  16512.000000  16512.000000        16512.000000  16512.000000   \n",
       "mean    -119.575635     35.639314           28.653404   2622.539789   \n",
       "std        2.001828      2.137963           12.574819   2138.417080   \n",
       "min     -124.350000     32.540000            1.000000      6.000000   \n",
       "25%     -121.800000     33.940000           18.000000   1443.000000   \n",
       "50%     -118.510000     34.260000           29.000000   2119.000000   \n",
       "75%     -118.010000     37.720000           37.000000   3141.000000   \n",
       "max     -114.310000     41.950000           52.000000  39320.000000   \n",
       "\n",
       "       total_bedrooms    population    households  median_income  \n",
       "count    16512.000000  16512.000000  16512.000000   16512.000000  \n",
       "mean       533.939438   1419.687379    497.011810       3.875884  \n",
       "std        410.806260   1115.663036    375.696156       1.904931  \n",
       "min          2.000000      3.000000      2.000000       0.499900  \n",
       "25%        296.000000    784.000000    279.000000       2.566950  \n",
       "50%        433.000000   1164.000000    408.000000       3.541550  \n",
       "75%        641.000000   1719.000000    602.000000       4.745325  \n",
       "max       6210.000000  35682.000000   5358.000000      15.000100  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = imputer.transform(housing_num)\n",
    "\n",
    "# This X vairable is a plain NumPy array, let's put it back into a pandas DataFrame object:\n",
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)\n",
    "\n",
    "housing_tr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00afbb3",
   "metadata": {},
   "source": [
    "Scikit-Learn Design have some main design principles:\n",
    "\n",
    "* Consistency:\n",
    "  ***All objects share a consistent and simple interface:***\n",
    "     + Estimators:\n",
    "     \n",
    "         - Any object that can estimate some parameters based on a dataset is called an *estimator* (e.g. an *imputer* is an estimator). The estimation itself is performer by *fit( )* method, and it takes only a parameter (or two for supervised learning algorithms; the second dataset contains the labels). Any other parameter needed to guide the estiation process is considered a hyperparameter (such as an impter's strategy), and it must be set as an instance variable (geberally via a constructor parameter).\n",
    "         \n",
    "     + Transformers:\n",
    "     \n",
    "         - Some estimators (such as  an imputer) can also transform a dataset; these are called *transformers*. Once again, the API is simple; the transformation generally relies on the learned parameters, as is the case for an imputer. All transformers also have a convenience method called *fit_transform( )* that is equivalent to calling *fit( )* and then *transform( )* is optimized and runs much faster).\n",
    "         \n",
    "     + Predictors:\n",
    "     \n",
    "         - Some estimatros, given a dataset, are capable of making predictions; they are called *predictors*. For example, the **LinearRegression** model of Scikit-Learn. A predictor has a *predict( )* method that takes a dataset of new instances and returns a dataset of corresponding predictions. It also has a *score( )* method that measures the quality of the predicitions, given a test set (and the corresponding labels, in the case of supervised learning algorithms).\n",
    "\n",
    "* Inspection:\n",
    "    - ***All the estimator's hyperparameters are acessible directly via public instance variables (e.g. imputer.strategy), and all the estimator's learned parameters are acessible via public instance variables with an underscore suffix (e.g. imputer.statistics_)***.\n",
    "    \n",
    "* Nonproliferation of classes:\n",
    "    - ***Datasets are represented as NumPy arrays or SciPy sparse matrices, instead of homemade classes. Hyperparameters are just regular Python strings numbers***.\n",
    "\n",
    "* Composition:\n",
    "    - ***Existing building blocks are reused as much as possible. For example, it is easy to create a *Pipeline* estimator from an arbitrary sequence of transformers followed by a final estimator, as we will see.***\n",
    "    \n",
    "* Sensible defaults:\n",
    "    - ***Scikit-Learn provides reasonable default values for most parameters, making it easy to quickly create a baseline working system.***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b26774",
   "metadata": {},
   "source": [
    "Let's take a look at text attributes, in our housing dataset we have only one: ``ocean_proximity``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b47b1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12655</th>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15502</th>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14053</th>\n",
       "      <td>NEAR OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20496</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18125</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5830</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17989</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>&lt;1H OCEAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ocean_proximity\n",
       "12655          INLAND\n",
       "15502      NEAR OCEAN\n",
       "2908           INLAND\n",
       "14053      NEAR OCEAN\n",
       "20496       <1H OCEAN\n",
       "1481         NEAR BAY\n",
       "18125       <1H OCEAN\n",
       "5830        <1H OCEAN\n",
       "17989       <1H OCEAN\n",
       "4861        <1H OCEAN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aaf767",
   "metadata": {},
   "source": [
    "It's not arbitrary text, there are a limited nujmber of possible values, each of which represents a category. Let's convert this finite set of possibilities of words to numbers, using ``OrdinalEncoder``, by Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed4b867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "\n",
    "# show the 10 first values:\n",
    "print(type(housing_cat_encoded), '\\n\\n')\n",
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b7fa4",
   "metadata": {},
   "source": [
    "This function auto generate a list of categories that is present in the ``housing_cat``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3b439a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a0a904",
   "metadata": {},
   "source": [
    "One issue with this representation is that ML algorithms will assume that two nearby values are most similiar than two distant values. This may be fine in some cases (e.g. for ordered categories such as *bad*, *average*, *good*, and *excellent*).\n",
    "\n",
    "Another way to organize this information is using the ``OneHotEncoder``, where we select a variable present in the list (let's chose \"<1H OCEAN\") to be 1 (hot), and the remainder of the variables are 0 (we can call this variable for *dummy attributes*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4ef99d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16512x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "\n",
    "# Inspecting the variable:\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089337ea",
   "metadata": {},
   "source": [
    "Here we get a SciPy sparse matrix, we can convert this object to NumPy arrray just calling ``toarray( )`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f94e5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5510eb5",
   "metadata": {},
   "source": [
    "Let's see the econder's categories_ instance variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8efc0c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'],\n",
       "       dtype=object)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d228d6",
   "metadata": {},
   "source": [
    "### Custom Transformers\n",
    "\n",
    "Scikit-Learn provides many useful transformers, you will need to write your own for tasks such as custom cleanup oerations or combining specific attributes. \n",
    "If you add *BaseEstimator* as a base class, you will be useful for automatic hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3831183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X [:, households_ix]\n",
    "        \n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "        \n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "        \n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b9b127",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "Machine Learning algorithms don't perform well when the input numerical attributes have very different scales. That is the case for the housing data: the total number of rooms ranges from about 6 yo 39.320, while the median incomes only range from 0 to 15. Note that scaling the target values is generally not required.\n",
    "\n",
    "There are two common ways to get all attributes to have the same scale: *min-max scaling* and *standadization*.\n",
    "\n",
    "#### Min-max scaling (normalization)\n",
    "\n",
    "Values are shifted and rescaled so that they end up ranging from 0 to 1. We do this by subtracting the min value and dividing by the max minus the min. Scikit-Learn provides a transformer called ``MinMaxScaler`` for this. \n",
    "\n",
    "#### Standardization\n",
    "first subtracts the mean value (i.e. standardized vaues alaways have zero mean), and then it divides by the standard deviation so that the resulting distribution has unit variance.\n",
    "\n",
    "\n",
    "Unlike min-max scaling, standardzation does not bound values to a specific range, which may be a problem for some algortihms (e.g. neural networks often expect an input value ranging from 0 to 1).\n",
    "\n",
    " - Standardzation is much less affected by outliers than Normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2221436c",
   "metadata": {},
   "source": [
    "# Transformation Pipelines\n",
    "\n",
    "Scikit-Learn provides the ``Pipeline`` class to help with such sequences of transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f101fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('attribs_adder', CombinedAttributesAdder()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b8f2da",
   "metadata": {},
   "source": [
    "The pipeline constructor takes a list of name/estimator pairs defining a sequence of steps. All but the last estimator must be trasformers (i.e. they must have a *fit_transform( )* method).\n",
    "\n",
    "So far, we have handled the categorical columns and the numerical columns separately. It would be more convenient to have a single transformer able to handle all coluimns, applying the appropriate transformations to each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "01fc4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, num_attribs),\n",
    "    (\"cat\", OneHotEncoder(), cat_attribs)\n",
    "])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e35401c",
   "metadata": {},
   "source": [
    "Now, we get a complete pipeline!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
